{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92445c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import zipfile\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "406c5745",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)  # ì—´ ì „ì²´ í‘œì‹œ\n",
    "pd.set_option(\"display.width\", None)  # ê°€ë¡œ í­ ì œí•œ ì œê±°"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb2c516",
   "metadata": {},
   "source": [
    "### 0. data load & ì¼ë¶€ ìŠ¤íƒ€ì¼ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34db7246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¶ˆëŸ¬ì˜¨ json ê°œìˆ˜: 182290\n"
     ]
    }
   ],
   "source": [
    "zip_path = (\n",
    "    \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ë¼ë²¨ë§ë°ì´í„°.zip\"\n",
    ")\n",
    "styles = [\n",
    "    \"ë¡œë§¨í‹±/\",\n",
    "    \"ì„¹ì‹œ/\",\n",
    "    \"ì†Œí”¼ìŠ¤íŠ¸ì¼€ì´í‹°ë“œ/\",\n",
    "    \"ìŠ¤í¬í‹°/\",\n",
    "    \"í´ë˜ì‹/\",\n",
    "    \"ì  ë”ë¦¬ìŠ¤/\",\n",
    "    \"ì•„ë°©ê°€ë¥´ë“œ/\",\n",
    "]\n",
    "\n",
    "json_list = []\n",
    "\n",
    "with zipfile.ZipFile(zip_path, \"r\") as z:\n",
    "    for info in z.infolist():\n",
    "        real_name = info.filename.encode(\"cp437\").decode(\"cp949\")\n",
    "\n",
    "        # ìœ„ ìŠ¤íƒ€ì¼ í´ë”ë“¤ ì¤‘ í•˜ë‚˜ì— ì†í•˜ë©´ì„œ .json ì¸ íŒŒì¼ë§Œ\n",
    "        if any(s in real_name for s in styles) and real_name.endswith(\".json\"):\n",
    "            with z.open(info.filename) as f:\n",
    "                data = json.load(f)\n",
    "                json_list.append(data)\n",
    "\n",
    "print(f\"ë¶ˆëŸ¬ì˜¨ json ê°œìˆ˜: {len(json_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "961d987c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 182290 entries, 0 to 182289\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count   Dtype \n",
      "---  ------                       --------------   ----- \n",
      " 0   ì´ë¯¸ì§€ ì •ë³´.ì´ë¯¸ì§€ ì‹ë³„ì               182290 non-null  int64 \n",
      " 1   ì´ë¯¸ì§€ ì •ë³´.ì´ë¯¸ì§€ ë†’ì´                182290 non-null  int64 \n",
      " 2   ì´ë¯¸ì§€ ì •ë³´.ì´ë¯¸ì§€ íŒŒì¼ëª…               182290 non-null  object\n",
      " 3   ì´ë¯¸ì§€ ì •ë³´.ì´ë¯¸ì§€ ë„ˆë¹„                182290 non-null  int64 \n",
      " 4   ë°ì´í„°ì…‹ ì •ë³´.íŒŒì¼ ìƒì„±ì¼ì              182290 non-null  object\n",
      " 5   ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë ‰íŠ¸ì¢Œí‘œ.ì•„ìš°í„°   182290 non-null  object\n",
      " 6   ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë ‰íŠ¸ì¢Œí‘œ.í•˜ì˜    182290 non-null  object\n",
      " 7   ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë ‰íŠ¸ì¢Œí‘œ.ì›í”¼ìŠ¤   182290 non-null  object\n",
      " 8   ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë ‰íŠ¸ì¢Œí‘œ.ìƒì˜    182290 non-null  object\n",
      " 9   ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….í´ë¦¬ê³¤ì¢Œí‘œ.ì•„ìš°í„°  182290 non-null  object\n",
      " 10  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….í´ë¦¬ê³¤ì¢Œí‘œ.í•˜ì˜   182290 non-null  object\n",
      " 11  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….í´ë¦¬ê³¤ì¢Œí‘œ.ì›í”¼ìŠ¤  182290 non-null  object\n",
      " 12  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….í´ë¦¬ê³¤ì¢Œí‘œ.ìƒì˜   182290 non-null  object\n",
      " 13  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ìŠ¤íƒ€ì¼    182290 non-null  object\n",
      " 14  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ì•„ìš°í„°    182290 non-null  object\n",
      " 15  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.í•˜ì˜     182290 non-null  object\n",
      " 16  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ì›í”¼ìŠ¤    182290 non-null  object\n",
      " 17  ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ìƒì˜     182290 non-null  object\n",
      " 18  ë°ì´í„°ì…‹ ì •ë³´.íŒŒì¼ ë²ˆí˜¸                182290 non-null  int64 \n",
      " 19  ë°ì´í„°ì…‹ ì •ë³´.íŒŒì¼ ì´ë¦„                182290 non-null  object\n",
      "dtypes: int64(4), object(16)\n",
      "memory usage: 27.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# DataFrame ìƒì„±\n",
    "df = pd.json_normalize(json_list)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce87c19",
   "metadata": {},
   "source": [
    "### 1. ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d713a9f",
   "metadata": {},
   "source": [
    "##### - í•„ìš”í•œ ì»¬ëŸ¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7131dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ ì»¬ëŸ¼ë§Œ\n",
    "df_filter = df.iloc[:, [0, 1, 2, 3, 6, 7, 8, 13, 14, 15, 16, 17]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a01ca6d",
   "metadata": {},
   "source": [
    "##### - ë¹ˆ ë”•ì…”ë„ˆë¦¬ nanìœ¼ë¡œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c928fe42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25100\\393704689.py:10: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  mask = df_filter[obj_cols].applymap(is_empty_list_dict)\n"
     ]
    }
   ],
   "source": [
    "# ë¹ˆ ë”•ì…”ë„ˆë¦¬ nanìœ¼ë¡œ\n",
    "df_filter = df_filter.copy()\n",
    "obj_cols = df_filter.select_dtypes(include=\"object\").columns\n",
    "\n",
    "\n",
    "def is_empty_list_dict(x):\n",
    "    return isinstance(x, list) and (x == [] or x == [{}])\n",
    "\n",
    "\n",
    "mask = df_filter[obj_cols].applymap(is_empty_list_dict)\n",
    "\n",
    "df_filter.loc[:, obj_cols] = df_filter[obj_cols].mask(mask, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bde5d",
   "metadata": {},
   "source": [
    "##### - ì•„ìš°í„° ìˆëŠ” ë°ì´í„° ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb49a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì•„ìš°í„° ìˆëŠ” ë°ì´í„° ì œê±° í›„ ê°œìˆ˜: 140058\n"
     ]
    }
   ],
   "source": [
    "# 'ì•„ìš°í„°' ê°’ì´ ì¡´ì¬í•˜ëŠ” í–‰ ì œê±°\n",
    "df_filter = df_filter[df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ì•„ìš°í„°\"].isna()]\n",
    "print(\"ì•„ìš°í„° ìˆëŠ” ë°ì´í„° ì œê±° í›„ ê°œìˆ˜:\", len(df_filter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc82e2a",
   "metadata": {},
   "source": [
    "##### - [ìƒì˜&í•˜ì˜ or ì›í”¼ìŠ¤]ì˜ ë°ì´í„°ë§Œ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1bcf84ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì˜ & í•˜ì˜ ëª¨ë‘ ë˜ëŠ” ì›í”¼ìŠ¤ë§Œ ì¡´ì¬í•˜ëŠ” í–‰\n",
    "df_filter = df_filter[\n",
    "    (\n",
    "        df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ìƒì˜\"].notna()\n",
    "        & df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.í•˜ì˜\"].notna()\n",
    "        & df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ì›í”¼ìŠ¤\"].isna()\n",
    "    )\n",
    "    | (\n",
    "        df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ì›í”¼ìŠ¤\"].notna()\n",
    "        & df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.ìƒì˜\"].isna()\n",
    "        & df_filter[\"ë°ì´í„°ì…‹ ì •ë³´.ë°ì´í„°ì…‹ ìƒì„¸ì„¤ëª….ë¼ë²¨ë§.í•˜ì˜\"].isna()\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cdedc5",
   "metadata": {},
   "source": [
    "##### - ë¼ë²¨ë§ ì»¬ëŸ¼ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "065cde3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»¬ëŸ¼ëª… ë³€ê²½\n",
    "df_filter.columns = [\n",
    "    \"ì‹ë³„ì\",\n",
    "    \"ì´ë¯¸ì§€ë†’ì´\",\n",
    "    \"íŒŒì¼ëª…\",\n",
    "    \"ì´ë¯¸ì§€ë„ˆë¹„\",\n",
    "    \"ë ‰íŠ¸ì¢Œí‘œ_í•˜ì˜\",\n",
    "    \"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\",\n",
    "    \"ë ‰íŠ¸ì¢Œí‘œ_ìƒì˜\",\n",
    "    \"ë¼ë²¨ë§_ìŠ¤íƒ€ì¼\",\n",
    "    \"ë¼ë²¨ë§_ì•„ìš°í„°\",\n",
    "    \"ë¼ë²¨ë§_í•˜ì˜\",\n",
    "    \"ë¼ë²¨ë§_ì›í”¼ìŠ¤\",\n",
    "    \"ë¼ë²¨ë§_ìƒì˜\",\n",
    "]\n",
    "df_filter = df_filter.drop([\"ë¼ë²¨ë§_ì•„ìš°í„°\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c174343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒŒì‹± í•¨ìˆ˜ ìƒì„±\n",
    "def expand_dict(val):\n",
    "    if isinstance(val, list) and len(val) > 0 and isinstance(val[0], dict):\n",
    "        return val[0]\n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e2d1e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìŠ¤íƒ€ì¼, ì„œë¸ŒìŠ¤íƒ€ì¼ íŒŒì‹±\n",
    "parsed = df_filter[\"ë¼ë²¨ë§_ìŠ¤íƒ€ì¼\"].apply(expand_dict).apply(pd.Series)\n",
    "df_parsed = pd.concat([df_filter, parsed], axis=1)\n",
    "\n",
    "# í•˜ì˜ ë¼ë²¨ë§ íŒŒì‹±\n",
    "parsed_add = df_filter[\"ë¼ë²¨ë§_í•˜ì˜\"].apply(expand_dict).apply(pd.Series)\n",
    "\n",
    "parsed_add[\"ì†Œì¬\"] = parsed_add[\"ì†Œì¬\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "parsed_add[\"í”„ë¦°íŠ¸\"] = parsed_add[\"í”„ë¦°íŠ¸\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "parsed_add = parsed_add.add_prefix(\"í•˜ì˜_\")\n",
    "df_parsed = pd.concat([df_parsed, parsed_add], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbac5c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›í”¼ìŠ¤ ë¼ë²¨ë§ íŒŒì‹±\n",
    "parsed_add = df_filter[\"ë¼ë²¨ë§_ì›í”¼ìŠ¤\"].apply(expand_dict).apply(pd.Series)\n",
    "\n",
    "parsed_add[\"ë””í…Œì¼\"] = parsed_add[\"ë””í…Œì¼\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "parsed_add[\"ì†Œì¬\"] = parsed_add[\"ì†Œì¬\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "parsed_add[\"í”„ë¦°íŠ¸\"] = parsed_add[\"í”„ë¦°íŠ¸\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "\n",
    "parsed_add = parsed_add.add_prefix(\"ì›í”¼ìŠ¤_\")\n",
    "df_parsed = pd.concat([df_parsed, parsed_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef02a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì˜ ë¼ë²¨ë§ íŒŒì‹±\n",
    "parsed_add = df_filter[\"ë¼ë²¨ë§_ìƒì˜\"].apply(expand_dict).apply(pd.Series)\n",
    "\n",
    "parsed_add[\"ì†Œì¬\"] = parsed_add[\"ì†Œì¬\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "parsed_add[\"í”„ë¦°íŠ¸\"] = parsed_add[\"í”„ë¦°íŠ¸\"].apply(\n",
    "    lambda x: \", \".join(x) if isinstance(x, list) else x\n",
    ")\n",
    "\n",
    "parsed_add = parsed_add.add_prefix(\"ìƒì˜_\")\n",
    "\n",
    "df_parsed = pd.concat([df_parsed, parsed_add], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "abea222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ë²¨ë§_ë¡œ ì‹œì‘í•˜ëŠ” ì»¬ëŸ¼ëª… ì œê±° (íŒŒì‹±ì „ì˜ ì»¬ëŸ¼ ì œê±°)\n",
    "label_cols = [col for col in df_parsed.columns if col.startswith(\"ë¼ë²¨ë§_\")]\n",
    "df_parsed = df_parsed.drop(columns=label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39b6e3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98690, 39)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_parsed.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbd4cfd",
   "metadata": {},
   "source": [
    "##### _ì˜·ê¹ƒ, _ì„œë¸Œìƒ‰ìƒ ì»¬ëŸ¼ ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "004a388a",
   "metadata": {},
   "outputs": [],
   "source": [
    "suffixes = ('_ì˜·ê¹ƒ', '_ì„œë¸Œìƒ‰ìƒ')\n",
    "cols_to_drop = [col for col in df_parsed.columns if col.endswith(suffixes)]\n",
    "df_parsed = df_parsed.drop(columns=cols_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ece5fb",
   "metadata": {},
   "source": [
    "##### - ì¤‘ë³µ ì˜· ì œê±°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9472cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¹„êµ ëŒ€ìƒ ì»¬ëŸ¼ ê°œìˆ˜: 25\n",
      "ê¸°ì¡´ í–‰ ìˆ˜: 98690\n",
      "í•„í„°ë§ í›„ í–‰ ìˆ˜: 8248\n"
     ]
    }
   ],
   "source": [
    "# 1ì°¨ : ì—°ì†ëœ í–‰ì˜ ì •ë³´ê°€ 80% ì´ìƒ ìœ ì‚¬í• ì‹œ ì œê±°\n",
    "# ---------------------------------------\n",
    "# 1. ë¹„êµ ëŒ€ìƒ ì»¬ëŸ¼ ìë™ ì„ íƒ\n",
    "# ---------------------------------------\n",
    "target_cols = [\n",
    "    col for col in df_parsed.columns\n",
    "    if col.startswith((\"ìƒì˜_\", \"í•˜ì˜_\", \"ì›í”¼ìŠ¤_\"))\n",
    "]\n",
    "\n",
    "print(\"ë¹„êµ ëŒ€ìƒ ì»¬ëŸ¼ ê°œìˆ˜:\", len(target_cols))\n",
    "\n",
    "# ---------------------------------------\n",
    "# 2. ê²°ì¸¡ì¹˜ í†µì¼\n",
    "# ---------------------------------------\n",
    "df_compare = df_parsed[target_cols].fillna(\"##NULL##\")\n",
    "\n",
    "# ---------------------------------------\n",
    "# 3. ì´ì „ í–‰ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "# ---------------------------------------\n",
    "df_shift = df_compare.shift(1)\n",
    "\n",
    "# True/False ë¹„êµ ê²°ê³¼\n",
    "match_matrix = (df_compare == df_shift)\n",
    "\n",
    "# í–‰ë³„ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "similarity_ratio = match_matrix.sum(axis=1) / len(target_cols)\n",
    "\n",
    "# ---------------------------------------\n",
    "# 4. ìœ ì‚¬ë„ 70% ì´ìƒ ì œê±°\n",
    "# ---------------------------------------\n",
    "threshold = 0.7\n",
    "\n",
    "df_filtered = df_parsed[similarity_ratio < threshold].reset_index(drop=True)\n",
    "\n",
    "print(\"ê¸°ì¡´ í–‰ ìˆ˜:\", len(df_parsed))\n",
    "print(\"í•„í„°ë§ í›„ í–‰ ìˆ˜:\", len(df_filtered))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1a7c9749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê¸°ì¡´ í–‰ ìˆ˜: 8248\n",
      "í•„í„°ë§ í›„ í–‰ ìˆ˜: 6109\n"
     ]
    }
   ],
   "source": [
    "# 2ì°¨ : ì—°ì†ëœ í–‰ì˜ ì œí’ˆëª…ê³¼ ìŠ¤íƒ€ì¼ì´ ë™ì¼í•œ ê²½ìš° ì œê±°\n",
    "df_filtered[\"ì œí’ˆëª…_ì•\"] = (\n",
    "    df_filtered[\"íŒŒì¼ëª…\"]\n",
    "    .str.split(\"_\")\n",
    "    .str[0]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "df_filtered[\"ìŠ¤íƒ€ì¼_clean\"] = (\n",
    "    df_filtered[\"ìŠ¤íƒ€ì¼\"]\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    ")\n",
    "\n",
    "mask = ~(\n",
    "    (df_filtered[\"ì œí’ˆëª…_ì•\"] == df_filtered[\"ì œí’ˆëª…_ì•\"].shift(1)) &\n",
    "    (df_filtered[\"ìŠ¤íƒ€ì¼_clean\"] == df_filtered[\"ìŠ¤íƒ€ì¼_clean\"].shift(1))\n",
    ")\n",
    "\n",
    "df_filtered_2 = df_filtered[mask].reset_index(drop=True)\n",
    "df_filtered_2 = df_filtered_2.drop(columns=[\"ì œí’ˆëª…_ì•\", \"ìŠ¤íƒ€ì¼_clean\"])\n",
    "\n",
    "print(\"ê¸°ì¡´ í–‰ ìˆ˜:\", len(df_filtered))\n",
    "print(\"í•„í„°ë§ í›„ í–‰ ìˆ˜:\", len(df_filtered_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1035d367",
   "metadata": {},
   "source": [
    "### 2. [UIìš©]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba741515",
   "metadata": {},
   "source": [
    "##### - ì´ë¯¸ì§€ ìë¥´ê¸°(crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "acc65cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_25100\\2606698141.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_xy[\"ì‹ë³„ì\"] = df_xy[\"ì‹ë³„ì\"].astype(str) + \".jpg\"\n"
     ]
    }
   ],
   "source": [
    "# ì¢Œí‘œì •ë³´ë§Œ\n",
    "df_xy = df_filtered_2[\n",
    "    [\"ì‹ë³„ì\", \"ìŠ¤íƒ€ì¼\", \"ë ‰íŠ¸ì¢Œí‘œ_ìƒì˜\", \"ë ‰íŠ¸ì¢Œí‘œ_í•˜ì˜\", \"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\"]\n",
    "]\n",
    "# ì‹ë³„ì ì»¬ëŸ¼ì„ íŒŒì¼ëª…ìœ¼ë¡œ\n",
    "df_xy[\"ì‹ë³„ì\"] = df_xy[\"ì‹ë³„ì\"].astype(str) + \".jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "538b92fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìë¥¸ ì´ë¯¸ì§€ ì €ì¥í•  í´ë”\n",
    "base_save_folder = \"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/\"\n",
    "for part in [\"ìƒì˜\", \"í•˜ì˜\", \"ì›í”¼ìŠ¤\"]:\n",
    "    os.makedirs(os.path.join(base_save_folder, part), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa21d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê° ìŠ¤íƒ€ì¼ì´ ì–´ëŠ zipì— ìˆëŠ”ì§€\n",
    "style_to_zip = {\n",
    "    \"ë¡œë§¨í‹±\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_1.zip\",\n",
    "    \"ì„¹ì‹œ\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_1.zip\",\n",
    "    \"ì†Œí”¼ìŠ¤íŠ¸ì¼€ì´í‹°ë“œ\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_1.zip\",\n",
    "    \"ìŠ¤í¬í‹°\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_3.zip\",\n",
    "    \"ì•„ë°©ê°€ë¥´ë“œ\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_3.zip\",\n",
    "    \"í´ë˜ì‹\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_3.zip\",\n",
    "    \"ì  ë”ë¦¬ìŠ¤\": \"C:/Users/Admin/Desktop/PROJ/data/01_raw/K-Fashion ì´ë¯¸ì§€/Training/ì›ì²œë°ì´í„°_3.zip\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c85c92fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# crop function\n",
    "def crop_and_save_by_part(df, zip_folder_map, base_save_folder, batch_size=100):\n",
    "    zip_cache = {}\n",
    "\n",
    "    for start in range(0, len(df), batch_size):\n",
    "        batch = df.iloc[start : start + batch_size]\n",
    "        print(f\"Processing batch {start} ~ {start + len(batch) - 1}\")\n",
    "\n",
    "        for idx, row in batch.iterrows():\n",
    "            style = row[\"ìŠ¤íƒ€ì¼\"]\n",
    "            zip_path = zip_folder_map.get(style)\n",
    "            if zip_path is None:\n",
    "                print(f\"{style} ì¹´í…Œê³ ë¦¬ì˜ zip íŒŒì¼ì´ ì •ì˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "                continue\n",
    "\n",
    "            # zip ìºì‹œ\n",
    "            if zip_path not in zip_cache:\n",
    "                zip_cache[zip_path] = zipfile.ZipFile(zip_path, \"r\")\n",
    "            z = zip_cache[zip_path]\n",
    "\n",
    "            img_files = [name for name in z.namelist() if name.endswith(row[\"ì‹ë³„ì\"])]\n",
    "            if img_files:\n",
    "                img_zip_path = img_files[0]\n",
    "            if img_zip_path in z.namelist():\n",
    "                with z.open(img_zip_path) as f:\n",
    "                    img = Image.open(f).convert(\"RGB\")\n",
    "                    img_w, img_h = img.size\n",
    "\n",
    "                    # ì»¬ëŸ¼ë³„ ì²˜ë¦¬\n",
    "                    for col in [\"ë ‰íŠ¸ì¢Œí‘œ_ìƒì˜\", \"ë ‰íŠ¸ì¢Œí‘œ_í•˜ì˜\", \"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\"]:\n",
    "                        rects = row.get(col)\n",
    "                        if pd.isna(rects):\n",
    "                            continue\n",
    "                        part_name = col.split(\"_\")[\n",
    "                            -1\n",
    "                        ]  # ì»¬ëŸ¼ëª…ì—ì„œ ìƒì˜, í•˜ì˜, ì›í”¼ìŠ¤ ì¶”ì¶œ\n",
    "                        save_folder = os.path.join(base_save_folder, part_name)\n",
    "\n",
    "                        for i, r in enumerate(rects):\n",
    "\n",
    "                            # í‚¤ í™•ì¸\n",
    "                            if not all(\n",
    "                                k in r for k in [\"Xì¢Œí‘œ\", \"Yì¢Œí‘œ\", \"ê°€ë¡œ\", \"ì„¸ë¡œ\"]\n",
    "                            ):\n",
    "                                continue\n",
    "\n",
    "                            # ì¢Œí‘œ ì •ìˆ˜í™” + ë³´ì •\n",
    "                            x = max(0, int(float(r[\"Xì¢Œí‘œ\"])))\n",
    "                            y = max(0, int(float(r[\"Yì¢Œí‘œ\"])))\n",
    "                            w = int(float(r[\"ê°€ë¡œ\"]))\n",
    "                            h = int(float(r[\"ì„¸ë¡œ\"]))\n",
    "\n",
    "                            if w <= 0 or h <= 0:\n",
    "                                continue\n",
    "\n",
    "                            x2 = min(img_w, x + w)\n",
    "                            y2 = min(img_h, y + h)\n",
    "\n",
    "                            if x >= x2 or y >= y2:\n",
    "                                continue\n",
    "                            cropped = img.crop((x, y, x2, y2))\n",
    "                            save_path = os.path.join(\n",
    "                                save_folder,\n",
    "                                f\"{style}_{row['ì‹ë³„ì'].replace('.jpg','')}_{part_name}.jpg\",\n",
    "                            )\n",
    "                            cropped.save(save_path)\n",
    "            else:\n",
    "                print(f\"{img_zip_path} íŒŒì¼ì´ zip ì•ˆì— ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # zip ë‹«ê¸°\n",
    "    for z in zip_cache.values():\n",
    "        z.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56868aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing batch 0 ~ 99\n",
      "Processing batch 100 ~ 199\n",
      "Processing batch 200 ~ 299\n",
      "Processing batch 300 ~ 399\n",
      "Processing batch 400 ~ 499\n",
      "Processing batch 500 ~ 599\n",
      "Processing batch 600 ~ 699\n",
      "Processing batch 700 ~ 799\n",
      "Processing batch 800 ~ 899\n",
      "Processing batch 900 ~ 999\n",
      "Processing batch 1000 ~ 1099\n",
      "Processing batch 1100 ~ 1199\n",
      "Processing batch 1200 ~ 1299\n",
      "Processing batch 1300 ~ 1399\n",
      "Processing batch 1400 ~ 1499\n",
      "Processing batch 1500 ~ 1599\n",
      "Processing batch 1600 ~ 1699\n",
      "Processing batch 1700 ~ 1799\n",
      "Processing batch 1800 ~ 1899\n",
      "Processing batch 1900 ~ 1999\n",
      "Processing batch 2000 ~ 2099\n",
      "Processing batch 2100 ~ 2199\n",
      "Processing batch 2200 ~ 2299\n",
      "Processing batch 2300 ~ 2399\n",
      "Processing batch 2400 ~ 2499\n",
      "Processing batch 2500 ~ 2599\n",
      "Processing batch 2600 ~ 2699\n",
      "Processing batch 2700 ~ 2799\n",
      "Processing batch 2800 ~ 2899\n",
      "Processing batch 2900 ~ 2999\n",
      "Processing batch 3000 ~ 3099\n",
      "Processing batch 3100 ~ 3199\n",
      "Processing batch 3200 ~ 3299\n",
      "Processing batch 3300 ~ 3399\n",
      "Processing batch 3400 ~ 3499\n",
      "Processing batch 3500 ~ 3599\n",
      "Processing batch 3600 ~ 3699\n",
      "Processing batch 3700 ~ 3799\n",
      "Processing batch 3800 ~ 3899\n",
      "Processing batch 3900 ~ 3999\n",
      "Processing batch 4000 ~ 4099\n",
      "Processing batch 4100 ~ 4199\n",
      "Processing batch 4200 ~ 4299\n",
      "Processing batch 4300 ~ 4399\n",
      "Processing batch 4400 ~ 4499\n",
      "Processing batch 4500 ~ 4599\n",
      "Processing batch 4600 ~ 4699\n",
      "Processing batch 4700 ~ 4799\n",
      "Processing batch 4800 ~ 4899\n",
      "Processing batch 4900 ~ 4999\n",
      "Processing batch 5000 ~ 5099\n",
      "Processing batch 5100 ~ 5199\n",
      "Processing batch 5200 ~ 5299\n",
      "Processing batch 5300 ~ 5399\n",
      "Processing batch 5400 ~ 5499\n",
      "Processing batch 5500 ~ 5599\n",
      "Processing batch 5600 ~ 5699\n",
      "Processing batch 5700 ~ 5799\n",
      "Processing batch 5800 ~ 5899\n",
      "Processing batch 5900 ~ 5999\n",
      "Processing batch 6000 ~ 6099\n",
      "Processing batch 6100 ~ 6108\n"
     ]
    }
   ],
   "source": [
    "# ì´ë¯¸ì§€ crop ì‹¤í–‰\n",
    "crop_and_save_by_part(df_xy, style_to_zip, base_save_folder, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea43273",
   "metadata": {},
   "source": [
    "##### - ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "823cab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… ë¹„êµí•  í´ë” 3ê°œ\n",
    "folders = [\n",
    "    r\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/ìƒì˜\",\n",
    "    r\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/í•˜ì˜\",\n",
    "    r\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/ì›í”¼ìŠ¤\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2453fe35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì „ì²´ jpg ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼\n",
      "ì´ ì´ë¯¸ì§€ ê°œìˆ˜: 10140\n",
      "\n",
      "ğŸ“Œ ìµœëŒ€ Width: 797 px\n",
      "í•´ë‹¹ ì´ë¯¸ì§€: C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/ì›í”¼ìŠ¤\\ë¡œë§¨í‹±_118031_ì›í”¼ìŠ¤.jpg\n",
      "\n",
      "ğŸ“Œ ìµœëŒ€ Height: 1262 px\n",
      "í•´ë‹¹ ì´ë¯¸ì§€: C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/1.cropped_images/í•˜ì˜\\ì†Œí”¼ìŠ¤íŠ¸ì¼€ì´í‹°ë“œ_523387_í•˜ì˜.jpg\n"
     ]
    }
   ],
   "source": [
    "# âœ… jpg ì „ìš©\n",
    "image_extensions = ('.jpg', '.jpeg')\n",
    "\n",
    "max_width = 0\n",
    "max_height = 0\n",
    "\n",
    "max_width_image = \"\"\n",
    "max_height_image = \"\"\n",
    "\n",
    "total_images = 0\n",
    "\n",
    "for folder in folders:\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        for file in files:\n",
    "\n",
    "            if file.lower().endswith(image_extensions):\n",
    "                total_images += 1\n",
    "                file_path = os.path.join(root, file)\n",
    "\n",
    "                try:\n",
    "                    with Image.open(file_path) as img:\n",
    "                        w, h = img.width, img.height\n",
    "\n",
    "                        # ìµœëŒ€ ë„ˆë¹„ ì—…ë°ì´íŠ¸\n",
    "                        if w > max_width:\n",
    "                            max_width = w\n",
    "                            max_width_image = file_path\n",
    "\n",
    "                        # ìµœëŒ€ ë†’ì´ ì—…ë°ì´íŠ¸\n",
    "                        if h > max_height:\n",
    "                            max_height = h\n",
    "                            max_height_image = file_path\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"ì´ë¯¸ì§€ ì—´ê¸° ì‹¤íŒ¨: {file_path} â†’ {e}\")\n",
    "\n",
    "print(\"\\nâœ… ì „ì²´ jpg ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼\")\n",
    "print(f\"ì´ ì´ë¯¸ì§€ ê°œìˆ˜: {total_images}\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ ìµœëŒ€ Width: {max_width} px\")\n",
    "print(f\"í•´ë‹¹ ì´ë¯¸ì§€: {max_width_image}\")\n",
    "\n",
    "print(f\"\\nğŸ“Œ ìµœëŒ€ Height: {max_height} px\")\n",
    "print(f\"í•´ë‹¹ ì´ë¯¸ì§€: {max_height_image}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f233b072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ì´ 10140ê°œì˜ ì´ë¯¸ì§€ê°€ 797x1262 í¬ê¸°ë¡œ í†µì¼ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# âœ… ê²°ê³¼ ì €ì¥ í´ë”\n",
    "output_base = r\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/2.resized_images\"\n",
    "os.makedirs(output_base, exist_ok=True)\n",
    "\n",
    "# âœ… ëª©í‘œ í¬ê¸°\n",
    "TARGET_WIDTH = max_width\n",
    "TARGET_HEIGHT = max_height\n",
    "\n",
    "image_extensions = ('.jpg', '.jpeg')\n",
    "\n",
    "def resize_and_pad(image, target_w, target_h):\n",
    "    original_w, original_h = image.size\n",
    "\n",
    "    # âœ… ë¹„ìœ¨ ìœ ì§€\n",
    "    ratio = min(target_w / original_w, target_h / original_h)\n",
    "    new_size = (int(original_w * ratio), int(original_h * ratio))\n",
    "\n",
    "    resized_img = image.resize(new_size, Image.LANCZOS)\n",
    "\n",
    "    # âœ… í°ìƒ‰ ë°°ê²½\n",
    "    new_image = Image.new(\"RGB\", (target_w, target_h), (255, 255, 255))\n",
    "\n",
    "    # âœ… ì¤‘ì•™ ì •ë ¬\n",
    "    paste_x = (target_w - new_size[0]) // 2\n",
    "    paste_y = (target_h - new_size[1]) // 2\n",
    "\n",
    "    new_image.paste(resized_img, (paste_x, paste_y))\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "for folder in folders:\n",
    "    category = os.path.basename(folder)  # ìƒì˜ / í•˜ì˜ / ì›í”¼ìŠ¤\n",
    "    category_output = os.path.join(output_base, category)\n",
    "    os.makedirs(category_output, exist_ok=True)\n",
    "\n",
    "    for root, _, files in os.walk(folder):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(image_extensions):\n",
    "\n",
    "                input_path = os.path.join(root, file)\n",
    "\n",
    "                # âœ… íŒŒì¼ëª… ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ prefix ì¶”ê°€\n",
    "                new_filename = f\"{file}\"\n",
    "                output_path = os.path.join(category_output, new_filename)\n",
    "\n",
    "                try:\n",
    "                    with Image.open(input_path) as img:\n",
    "                        final_img = resize_and_pad(img, TARGET_WIDTH, TARGET_HEIGHT)\n",
    "                        final_img.save(output_path, quality=95)\n",
    "                        count += 1\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"ì‹¤íŒ¨: {input_path} â†’ {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ì´ {count}ê°œì˜ ì´ë¯¸ì§€ê°€ {TARGET_WIDTH}x{TARGET_HEIGHT} í¬ê¸°ë¡œ í†µì¼ë˜ì–´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2cfbfe",
   "metadata": {},
   "source": [
    "##### - ì¹´í…Œê³ ë¦¬/ìƒ‰ìƒë³„ í´ë”í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "239eaf4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ì›ë³¸ ë³´ì¡´ + ì‚¬ë³¸ ë¶„ë¥˜ ì™„ë£Œ! ===\n"
     ]
    }
   ],
   "source": [
    "#base_dir = r\"C:/Users/Admin/Desktop/ì´ì •ìˆ˜/LG U+/í”„ë¡œì íŠ¸3/data\" # ì •ìˆ˜\n",
    "base_dir = r\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes\" # ì›ì„ \n",
    "\n",
    "cropped_dir = os.path.join(base_dir, \"2.resized_images\")\n",
    "output_dir = os.path.join(base_dir, \"3.categorized_images\")\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def safe_str(x):\n",
    "    if pd.isna(x) or x in [\"\", None]:\n",
    "        return \"unknown\"\n",
    "    return str(x).strip().replace(\"/\", \"_\")\n",
    "\n",
    "\n",
    "for idx, row in df_filtered_2.iterrows():\n",
    "\n",
    "    style = safe_str(row[\"ìŠ¤íƒ€ì¼\"])\n",
    "    ident = safe_str(row[\"ì‹ë³„ì\"])\n",
    "\n",
    "    # ===============================\n",
    "    # 1) ì›í”¼ìŠ¤ ì²˜ë¦¬ (copy only)\n",
    "    # ===============================\n",
    "    if not pd.isna(row[\"ì›í”¼ìŠ¤_ì¹´í…Œê³ ë¦¬\"]):\n",
    "\n",
    "        filename = f\"{style}_{ident}_ì›í”¼ìŠ¤.jpg\"\n",
    "        src_path = os.path.join(cropped_dir, \"ì›í”¼ìŠ¤\", filename)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            category = safe_str(row[\"ì›í”¼ìŠ¤_ì¹´í…Œê³ ë¦¬\"])\n",
    "            color = safe_str(row[\"ì›í”¼ìŠ¤_ìƒ‰ìƒ\"])\n",
    "\n",
    "            dst_folder = os.path.join(output_dir, \"ì›í”¼ìŠ¤\", category, color)\n",
    "            os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "            shutil.copy(src_path, os.path.join(dst_folder, filename))\n",
    "\n",
    "        continue  # ì›í”¼ìŠ¤ëŠ” ì—¬ê¸°ì„œ ë\n",
    "\n",
    "    # ===============================\n",
    "    # 2) íˆ¬í”¼ìŠ¤(ìƒì˜ + í•˜ì˜) ì²˜ë¦¬\n",
    "    # ===============================\n",
    "\n",
    "    # â–¶ ìƒì˜ copy\n",
    "    if not pd.isna(row[\"ìƒì˜_ì¹´í…Œê³ ë¦¬\"]):\n",
    "        filename = f\"{style}_{ident}_ìƒì˜.jpg\"\n",
    "        src_path = os.path.join(cropped_dir, \"ìƒì˜\", filename)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            category = safe_str(row[\"ìƒì˜_ì¹´í…Œê³ ë¦¬\"])\n",
    "            color = safe_str(row[\"ìƒì˜_ìƒ‰ìƒ\"])\n",
    "\n",
    "            dst_folder = os.path.join(output_dir, \"ìƒì˜\", category, color)\n",
    "            os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "            shutil.copy(src_path, os.path.join(dst_folder, filename))\n",
    "\n",
    "    # â–¶ í•˜ì˜ copy\n",
    "    if not pd.isna(row[\"í•˜ì˜_ì¹´í…Œê³ ë¦¬\"]):\n",
    "        filename = f\"{style}_{ident}_í•˜ì˜.jpg\"\n",
    "        src_path = os.path.join(cropped_dir, \"í•˜ì˜\", filename)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            category = safe_str(row[\"í•˜ì˜_ì¹´í…Œê³ ë¦¬\"])\n",
    "            color = safe_str(row[\"í•˜ì˜_ìƒ‰ìƒ\"])\n",
    "\n",
    "            dst_folder = os.path.join(output_dir, \"í•˜ì˜\", category, color)\n",
    "            os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "            shutil.copy(src_path, os.path.join(dst_folder, filename))\n",
    "\n",
    "print(\"=== ì›ë³¸ ë³´ì¡´ + ì‚¬ë³¸ ë¶„ë¥˜ ì™„ë£Œ! ===\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89565910",
   "metadata": {},
   "source": [
    "### 3. [ë¶„ì„ìš©] ìƒ,í•˜ì˜/ì›í”¼ìŠ¤ table split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2036d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (1405, 14)\n"
     ]
    }
   ],
   "source": [
    "# 1. ì›í”¼ìŠ¤ ë°ì´í„°\n",
    "dress_exist_df = df_filtered_2[df_filtered_2[\"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\"].notna()]\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ê³µë°± ì œê±° (ì•ˆì „ì¥ì¹˜)\n",
    "dress_exist_df.columns = dress_exist_df.columns.str.strip()\n",
    "\n",
    "# ë°˜ë“œì‹œ í¬í•¨í•  ê¸°ë³¸ ì»¬ëŸ¼\n",
    "base_cols = [\"ì‹ë³„ì\", \"íŒŒì¼ëª…\", \"ìŠ¤íƒ€ì¼\", \"ì„œë¸ŒìŠ¤íƒ€ì¼\"]\n",
    "\n",
    "# ì›í”¼ìŠ¤ ê´€ë ¨ ì»¬ëŸ¼\n",
    "onepiece_cols = [\n",
    "    col\n",
    "    for col in dress_exist_df.columns\n",
    "    if col == \"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\" or col.startswith(\"ì›í”¼ìŠ¤_\")\n",
    "]\n",
    "\n",
    "# ìµœì¢… ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)\n",
    "selected_cols = [\n",
    "    col for col in base_cols if col in dress_exist_df.columns\n",
    "] + onepiece_cols\n",
    "\n",
    "# ì¶”ì¶œ\n",
    "onepiece_df = dress_exist_df[selected_cols]\n",
    "\n",
    "print(\"Shape:\", onepiece_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f82e7dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (4704, 22)\n"
     ]
    }
   ],
   "source": [
    "# 2. ìƒì˜, í•˜ì˜ ë°ì´í„°\n",
    "dress_nan_df = df_filtered_2[df_filtered_2[\"ë ‰íŠ¸ì¢Œí‘œ_ì›í”¼ìŠ¤\"].isna()]\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ê³µë°± ì œê±° (ì•ˆì „ì¥ì¹˜)\n",
    "dress_nan_df.columns = dress_nan_df.columns.str.strip()\n",
    "\n",
    "# ë°˜ë“œì‹œ í¬í•¨í•  ê¸°ë³¸ ì»¬ëŸ¼\n",
    "base_cols = [\"ì‹ë³„ì\", \"íŒŒì¼ëª…\", \"ìŠ¤íƒ€ì¼\", \"ì„œë¸ŒìŠ¤íƒ€ì¼\"]\n",
    "\n",
    "# ìƒì˜ ê´€ë ¨ ì»¬ëŸ¼\n",
    "top_cols = [\n",
    "    col\n",
    "    for col in dress_nan_df.columns\n",
    "    if col == \"ë ‰íŠ¸ì¢Œí‘œ_ìƒì˜\" or col.startswith(\"ìƒì˜_\")\n",
    "]\n",
    "\n",
    "# í•˜ì˜ ê´€ë ¨ ì»¬ëŸ¼\n",
    "bottoms_cols = [\n",
    "    col\n",
    "    for col in dress_nan_df.columns\n",
    "    if col == \"ë ‰íŠ¸ì¢Œí‘œ_í•˜ì˜\" or col.startswith(\"í•˜ì˜_\")\n",
    "]\n",
    "\n",
    "# ìµœì¢… ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°)\n",
    "selected_cols = (\n",
    "    [col for col in base_cols if col in dress_nan_df.columns] + top_cols + bottoms_cols\n",
    ")\n",
    "\n",
    "# ì¶”ì¶œ\n",
    "top_bottom_df = dress_nan_df[selected_cols]\n",
    "\n",
    "print(\"Shape:\", top_bottom_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87a4d3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "onepiece_df.to_csv(\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/0.onepiece_only.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")\n",
    "\n",
    "top_bottom_df.to_csv(\"C:/Users/Admin/Desktop/PROJ/data/02_cleaned/clothes/0.top_bottom_only.csv.csv\",\n",
    "    index=False,\n",
    "    encoding=\"utf-8-sig\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mycleanenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
